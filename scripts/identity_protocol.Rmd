---
title: "Identity Protocol for APCL project"
params:
 data_dir:  "seq03-33_identity"
 data_name:  "33-03_seq_identity"
---
# Workspace setup
```{r setup}
pacman::p_load(tidyverse, lubridate, here, clownfish, janitor, install=FALSE)
 # library(tidyverse)
 # library(lubridate)

# while db connection using helper file isn't working 
source("~/Documents/clownfish-pkg/R/db_connections.R")
leyte <- read_db("Leyte")
lab <- read_db("Laboratory")
```

This notebook continues where filtering and removing regenos left off, moving the genepop into cervus and processing identity results.
 
## Import the genepop to cervus
The genepop should be stored either on github and downloaded onto the windows machine.

###Open Cervus and convert the genepop to ceruvs:
 - Tools > Convert genotype file > Genepop to Cervus
 - A window will open, navigate to the genepop file that has been downloaded to the windows machine
 - Choose 2 digit format, do not use the first id as a population name
 **(2790 individuals, 1005 loci)**
 
### Run an allele frequency analysis:
 - Analysis > Allele frequency analysis
 - make sure the converted file is in the genotype file field
 * Yes Header Row
 * Yes Read Locus Names
 * ID in column 2
 * First allele in column 3
 * Type in number of loci from conversion (1447)
 * Save as “….._AF"
 * Leave all the output option boxes checked
  
### Run an identity analysis
 * Genotype file should be autofilled with the convert file created above
 * Yes Header Row
 * Id in column 2
 * First allele in column 3
 * Do not test sexes separately
 * Allele freq data should be autofilled with the AF file created above
 * Save as “…._ID"
 * Fill in minimum number of matching loci (80% of total = 804)
 * allow fuzzy matching with 10% mismatch (10% of total = 101)
 * don’t show all comparisons - this generates a HUGE csv of every single pairwise comparison.
 
### Upload the output to github, pull to mac
 
### Import the data into R
 
```{r}
idcsv_raw <- read_csv(here("data","seq03-33_identity", "33-03_seq_identity_ID.csv"), col_types = cols(
  `First ID` = col_character(),
  `Loci typed` = col_integer(),
  `Second ID` = col_character(),
  `Loci typed_1` = col_integer(),
  `Matching loci` = col_integer(),
  `Mismatching loci` = col_integer(),
  pID = col_double(),
  pIDsib = col_double(),
  Status = col_character()
)) 

names(idcsv_raw) <- c("first_id",  "first_loci_typed",  "second_id",  "second_loci_typed",  "matching_loci",  "mismatching_loci",  "p_id",  "p_id_sib",  "status")

# add mismatch rate
idcsv <- idcsv_raw %>%
  mutate(mismatch_prop = mismatching_loci/(mismatching_loci + matching_loci)) %>% 
  # order by number of matching loci
  arrange(matching_loci)
```


Plot proportion mismatch, pay attention to axis limits
```{r}

ggplot(idcsv, aes(x = matching_loci, y = mismatch_prop)) +
  geom_point() +
  theme_bw()
 
```

  ### Add sample_ids
```{r}
 # for first_sample_id
 temp <- idcsv %>% 
   rename(ligation_id = first_id)
 lab1 <- samp_from_lig(temp)
 names(lab1) <- paste("first_", names(lab1), sep = "")
 
 
 # for second_sample_id
 temp <- idcsv %>% 
   rename(ligation_id = second_id)
 lab2 <- samp_from_lig(temp)
 names(lab2) <- paste("second_", names(lab2), sep = "")
 
 # add the ids to the idcsv
  idcsv <- idcsv %>% 
    left_join(lab1, by = c("first_id" = "first_ligation_id")) %>% 
    left_join(lab2, by = c("second_id" = "second_ligation_id")) 

rm(lab1, lab2, temp)
```

### Add field data
```{r}
first <- fish_anem_dive() %>% 
  filter(sample_id %in% idcsv$first_sample_id)
names(first) <- paste0("first_", names(first))

sec <- fish_anem_dive() %>% 
  filter(sample_id %in% idcsv$second_sample_id)
names(sec) <- paste0("second_", names(sec))

idcsv <- left_join(idcsv, first, by = "first_sample_id") %>% 
  left_join(sec, by = "second_sample_id")

# rearrange columns
idcsv <- idcsv %>% 
  select(contains("first"), contains("second"), everything())

rm(first, sec)
```

## Get lat lons
```{r}

#find the lat lon of the first anem
first <- idcsv %>% 
  mutate(first_anem_obs_time = force_tz(ymd_hms(str_c(first_date, first_anem_obs_time, sep = " ")), tzone = "Asia/Manila")) %>% 
  mutate(first_anem_obs_time = with_tz(first_anem_obs_time, tzone = "UTC")) %>% 
  mutate(first_hour = hour(first_anem_obs_time), 
         first_minute = minute(first_anem_obs_time))

lat <- leyte %>%
    tbl("GPX")  %>% 
    mutate(gpx_date = date(time)) %>%
    filter(gpx_date %in% idcsv$first_date) %>% 
    mutate(gpx_hour = hour(time)) %>%
    mutate(minute = minute(time)) %>%
    mutate(second = second(time)) %>%
    select(-time, -second)%>%
    collect() 

# attach the lat lons
first <- left_join(first, lat, by = c("first_date" = "gpx_date", "first_hour" = "gpx_hour", "first_minute" = "minute", "first_gps" = "unit"))

# summarize the lat lons
first <- first %>% 
  group_by(first_id) %>% 
  summarise(first_lat = mean(as.numeric(lat)), 
            first_lon = mean(as.numeric(lon)))

idcsv <- left_join(idcsv, first, by = "first_id")
rm(first, lat)

# find the lat lon of the second anem
second <- idcsv %>% 
  mutate(second_anem_obs_time = force_tz(ymd_hms(str_c(second_date, second_anem_obs_time, sep = " ")), tzone = "Asia/Manila")) %>% 
  mutate(second_anem_obs_time = with_tz(second_anem_obs_time, tzone = "UTC")) %>% 
  mutate(second_hour = hour(second_anem_obs_time), 
         second_minute = minute(second_anem_obs_time))

lat <- leyte %>%
    tbl("GPX")  %>% 
    mutate(gpx_date = date(time)) %>%
    filter(gpx_date %in% idcsv$second_date) %>% 
    mutate(gpx_hour = hour(time)) %>%
    mutate(minute = minute(time)) %>%
    mutate(second = second(time)) %>%
    select(-time, -second)%>%
    collect() 

# attach the lat lons
second <- left_join(second, lat, by = c("second_date" = "gpx_date", "second_hour" = "gpx_hour", "second_minute" = "minute", "second_gps" = "unit"))

# summarize the lat lons
second <- second %>% 
  group_by(second_id) %>% 
  summarise(second_lat = mean(as.numeric(lat)), 
            second_lon = mean(as.numeric(lon)))

idcsv <- left_join(idcsv, second, by = "second_id")
rm(lat, second)  

```


# Write big table into a file -----------------------
```{r}
# write_csv(idcsv, here("data", params$data_dir, paste0(params$data_name, "_big_table.csv")))

# idcsv <- read_csv(here("data", params$data_dir, paste0(params$data_name, "_big_table.csv")))

# cleanup
# rm(alldists)
```
# Does the first gen_id match the second gen id?
```{r}
old_pairs <- idcsv %>% 
  filter(first_gen_id == second_gen_id, 
         !is.na(first_gen_id)) %>% 
  select(first_gen_id, second_gen_id, everything())
```


# Examine new matches
```{r}
new_pairs <- anti_join(idcsv, old_pairs) %>% 
  # reduce number of columns
  select(-contains("fish_spp"), -contains("fish_obs"), -contains("fin_id"), -contains("corr"), -contains("collect")) %>% 
  select(first_sample_id, second_sample_id, first_gen_id, second_gen_id, first_tag_id, second_tag_id, mismatching_loci, matching_loci, everything()) %>% 
  mutate(lat_diff = first_lat - second_lat, 
         lon_diff = first_lon - second_lon)
```

# Which fish are too far away to be obvious matches?  None.
```{r}
far_fish <- new_pairs %>% 
  filter(lon_diff > 50, lat_diff > 50)
```

# Which fish are tag recaptures? None
```{r}
tag_fish <- new_pairs %>% 
  filter(first_tag_id == second_tag_id)
```

# Which fish change sex?
```{r}
change_sex <- new_pairs %>% 
  filter(first_sex != second_sex) %>% 
  select(contains("size"), contains("sex"), contains("color"), contains("date"), everything())
```
# Assign gen_ids
```{r}
new_gen_ids <- new_pairs %>% 
  mutate(first_gen_id = ifelse(first_gen_id == 0, NA, first_gen_id),
         second_gen_id = ifelse(second_gen_id == 0, NA, second_gen_id),
    second_gen_id = ifelse(!is.na(first_gen_id), first_gen_id, second_gen_id)) %>% 
  select(contains("fish_table_id"), contains("gen_id"))

new_gen_ids <- new_gen_ids %>% 
  mutate(first_gen_id = ifelse(is.na(first_gen_id), second_gen_id, first_gen_id))

saveRDS(new_gen_ids, "~/Documents/leyteBuildDB/data/new-gen-ids_2019-04-15.RData")
```
# Next change the db with these new gen_ids

# Then run the recaptured-fish.Rmd protocol to make sure the gen_ids are all matched up.